# ğŸ§  PromptCraft Lab

**PromptCraft Lab** is a modular **LLM Workflow Assistant Suite** designed for **AI developers, power users, and teams** building applications with Large Language Models (LLMs).  
It helps you **organize, version, test, and optimize** prompts, track **token usage & cost analytics**, and run **LLM-assisted sessions** â€” all through a clean, API-first backend.

---

## ğŸš€ Features

### ğŸ§© Prompt Management
- Create and version prompts with metadata (tags, default model, description).
- Reuse across projects and share with team members.
- Built-in cost and performance tracking (tokens, latency, success rate).

### ğŸ§  Session & Context Tracking
- Structured conversational sessions with full message history.
- Context recall â€” reuse prior interactions in new sessions.
- Automatic logging of user â†” assistant exchanges.

### ğŸ“Š Usage Analytics & Cost Dashboard
- Token usage, response quality, and API cost aggregation.
- Detect abnormal token spikes and performance drops.
- Integration-ready for external observability (Grafana, Prometheus, etc).

### ğŸ” Output Validation Layer *(planned)*
- Optional LLM-based self-verification or RAG-based factual checks.
- Simple â€œresponse audit hooksâ€ to attach validation rules.

### âš™ï¸ Integration Hooks
- Lightweight REST API for any frontend or tool (VSCode, Jupyter, internal dashboards).
- Event hooks for async workflows (Redis-based queue ready).

---

## ğŸ§± Architecture

**Tech Stack:**
| Layer | Technology |
|-------|-------------|
| API Framework | [FastAPI](https://fastapi.tiangolo.com/) |
| ORM | [SQLAlchemy 2.0](https://docs.sqlalchemy.org/) |
| Database | PostgreSQL (Dockerized) |
| Caching / Queue | Redis |
| Dependency & Packaging | Poetry |
| Tests | Pytest + FastAPI TestClient |
| Auth & Config | Pydantic Settings |
| Containerization | Docker & Docker Compose |

### Directory Layout
```

promptcraft-lab/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py             # FastAPI app entrypoint
â”‚   â”œâ”€â”€ models.py           # SQLAlchemy ORM models
â”‚   â”œâ”€â”€ schemas.py          # Pydantic models
â”‚   â”œâ”€â”€ crud.py             # Database access layer
â”‚   â”œâ”€â”€ db.py               # Engine and session config
â”‚   â””â”€â”€ config.py           # Environment settings
â”œâ”€â”€ migrations/
â”‚   â””â”€â”€ 000_init.sql        # Schema definition (users, prompts, sessions, etc.)
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_api.py         # End-to-end API tests (mocked CRUD)
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md

````

---

## âš¡ Quickstart (Local Development)

### 1. Clone and setup
```bash
git clone https://github.com/harshit-singhania/promptcraft-lab.git
cd promptcraft-lab
poetry install
````

### 2. Start services

```bash
docker compose up -d db redis
```

### 3. Apply migrations

```bash
psql "postgresql://postgres:postgres@127.0.0.1:5432/llm_workflow" -f migrations/000_init.sql
```

### 4. Run API server

```bash
poetry run uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

Visit â†’ [http://localhost:8000/docs](http://localhost:8000/docs)

---

## âœ… Running Tests

All API routes are covered with mocked CRUD logic for isolated validation.

```bash
poetry run pytest -q
```

---

## ğŸ§© Example API Flow

```bash
# Create project
curl -s -X POST http://127.0.0.1:8000/api/v1/projects \
  -H "Content-Type: application/json" \
  -d '{"name":"Test Project","description":"for testing"}' | jq

# Create prompt
curl -s -X POST http://127.0.0.1:8000/api/v1/prompts \
  -H "Content-Type: application/json" \
  -d '{"project_id":"<project_id>","name":"Summarize","template":"Summarize: {{input}}"}' | jq

# Create session
curl -s -X POST http://127.0.0.1:8000/api/v1/sessions \
  -H "Content-Type: application/json" \
  -d '{"project_id":"<project_id>","title":"Exploration"}' | jq
```

---

## ğŸŒ Roadmap

| Stage | Feature                         | Status         |
| ----- | ------------------------------- | -------------- |
| 1     | Core API with CRUD & models     | âœ… Done         |
| 2     | Token usage analytics dashboard | ğŸ”„ In progress |
| 3     | LLM-assisted prompt grading     | ğŸ§© Planned     |
| 4     | Team auth & sharing             | ğŸ§© Planned     |
| 5     | SDK + web dashboard             | ğŸ§© Planned     |

---

## ğŸ§° For Developers

To run linters and hooks:

```bash
poetry run pre-commit run --all-files
```

To format automatically:

```bash
poetry run black .
poetry run isort .
```

---

## ğŸ§‘â€ğŸ’» Author

**Harshit Singhania**
AI Developer | Back-end Engineer | LLM Enthusiast
[GitHub](https://github.com/harshit-singhania)

---